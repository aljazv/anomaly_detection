{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import math\n",
    "import os\n",
    "\n",
    "import holoviews as hv\n",
    "import keras_metrics as km\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from influxdb import DataFrameClient\n",
    "from keras import Sequential\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import (LSTM, BatchNormalization, Dense, Dropout, Flatten,\n",
    "                          Input, RepeatVector, TimeDistributed)\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.merge import Concatenate, concatenate\n",
    "from keras.models import Model\n",
    "from numpy.random import seed\n",
    "from pylab import rcParams\n",
    "from scipy import stats\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import (auc, classification_report, confusion_matrix,\n",
    "                             f1_score, precision_recall_curve,\n",
    "                             precision_recall_fscore_support, recall_score,\n",
    "                             roc_curve)\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "import ricercando as ric\n",
    "\n",
    "database_ip = '46.101.250.119'\n",
    "ric.set_connection_params(host=database_ip)\n",
    "cli = DataFrameClient(database_ip, 8086, 'monroe', 'secure', 'monroe')\n",
    "cli.switch_database('monroe')\n",
    "\n",
    "seed(7)\n",
    "set_random_seed(11)\n",
    "rcParams['figure.figsize'] = 8, 6\n",
    "LABELS = [\"False\",\"True\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select nodes\n",
    "train_nodes = [\n",
    "    {\n",
    "        \"node_id\": '601',\n",
    "        \"ICCID\": '89390100001965067610',\n",
    "        \"start_time\": '2018-01-01',\n",
    "        \"end_time\": '2018-01-30'\n",
    "    },\n",
    "    {\n",
    "        \"node_id\": '608',\n",
    "        \"ICCID\": '8946071512360089522',\n",
    "        \"start_time\": '2018-01-01',\n",
    "        \"end_time\": '2018-01-30'\n",
    "    },\n",
    "    {\n",
    "        \"node_id\": '609',\n",
    "        \"ICCID\": '89460850007007786482',\n",
    "        \"start_time\": '2018-01-01',\n",
    "        \"end_time\": '2018-01-30'\n",
    "    },\n",
    "    {\n",
    "        \"node_id\": '610',\n",
    "        \"ICCID\": '8939104160000392272',\n",
    "        \"start_time\": '2018-01-01',\n",
    "        \"end_time\": '2018-01-30'\n",
    "    },\n",
    "    {\n",
    "        \"node_id\": '612',\n",
    "        \"ICCID\": '8939104160000392231',\n",
    "        \"start_time\": '2018-01-01',\n",
    "        \"end_time\": '2018-01-29'\n",
    "    },\n",
    "    {\n",
    "        \"node_id\": '613',\n",
    "        \"ICCID\": '89390100001965068626',\n",
    "        \"start_time\": '2018-01-01',\n",
    "        \"end_time\": '2018-01-29'\n",
    "    }\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input\n",
    "\n",
    "n_features = 1\n",
    "lookback = 240\n",
    "window_sizes = [1,5,10,20,40]\n",
    "\n",
    "X_scaled_windows = []\n",
    "\n",
    "# create input for every window\n",
    "for window_size in window_sizes:\n",
    "    X_array = []\n",
    "    y_array = []\n",
    "    \n",
    "    kfold_array_train = []\n",
    "    kfold_array_test = []\n",
    "    \n",
    "    index_for_cv = 0\n",
    "    \n",
    "    num_splits = 5\n",
    "    for i in range(num_splits):\n",
    "            kfold_array_train.append([])\n",
    "            kfold_array_test.append([])\n",
    "\n",
    "    for node in train_nodes:\n",
    "        node_id = node[\"node_id\"]\n",
    "        ICCID = node[\"ICCID\"]\n",
    "        start_time = node[\"start_time\"]\n",
    "        end_time = node[\"end_time\"]\n",
    "\n",
    "        datasets = cli.query(\"select * from class_1m where NodeId='{}' and time >= '{}' and time <= '{}' \".format(node_id,start_time,end_time))\n",
    "        df = ric.getdf(tables=\"ping\", nodeid=node_id,  start_time= start_time, end_time=end_time, freq=\"1m\")\n",
    "        df = df[df['Iccid'] == ICCID]\n",
    "\n",
    "        # merge together class and df\n",
    "        class_feature = datasets['class_1m'].copy()\n",
    "\n",
    "        class_feature = class_feature.drop(columns=['NodeId'])\n",
    "        class_feature.index = class_feature.index.tz_localize(None)\n",
    "        class_feature['time'] = class_feature.index\n",
    "        df['time'] = df.index\n",
    "        df.index.name = None\n",
    "        df = pd.merge(df, class_feature,  how='inner', left_on=['Iccid','time'], right_on = ['Iccid','time'])\n",
    "        df.index = df['time']\n",
    "        df = df.drop(columns=['time'])\n",
    "        df.index.name = 'time'\n",
    "        df_analise = df.copy()\n",
    "\n",
    "        # delay it for lookback value and predict from last element\n",
    "\n",
    "        df = df_analise.copy()\n",
    "        df = df.dropna(subset=['RTT'])\n",
    "        df.index = list(range(len(df.index)))\n",
    "        df = df[[\"RTT\",\"Class\"]]\n",
    "        df['Class'] = df['Class'].values * 1\n",
    "\n",
    "        df = df.fillna(0)      \n",
    "        df['RTT'] = df['RTT'].rolling(window_size, min_periods=1).mean()\n",
    "        \n",
    "        # create padding for empty values\n",
    "        \n",
    "        first_RTT = df['RTT'][0]\n",
    "        last_RTT = df['RTT'].values[-1]\n",
    "\n",
    "        for i in range((int(lookback/2))-1,-1,-1):\n",
    "            df['RTT_-{}'.format(i)] = df['RTT'].shift(periods=i).fillna(first_RTT)\n",
    "\n",
    "        for i in range(1,(int(lookback/2)+1),1):\n",
    "            df['RTT_{}'.format(i)] = df['RTT'].shift(periods=-i).fillna(last_RTT)\n",
    "\n",
    "        columns_list = list(df.columns.values)\n",
    "        features_names = list(filter(lambda x : \"RTT_\" in x, columns_list))\n",
    "\n",
    "\n",
    "        X = df[features_names].values\n",
    "        y = df[\"Class\"].values\n",
    "        \n",
    "        X_array.append(X)\n",
    "        y_array.append(y)\n",
    "\n",
    "        kfold = KFold(n_splits=num_splits, shuffle=False)\n",
    "        \n",
    "        number_of_rows = X.shape[0]\n",
    "        print(number_of_rows)\n",
    "        \n",
    "        # create fold indexes        \n",
    "        l = 0\n",
    "        for train, test in kfold.split(X, y):\n",
    "            \n",
    "            mod_train = list(map(lambda x: x + index_for_cv, train))\n",
    "            mod_test = list(map(lambda x: x + index_for_cv, test))\n",
    "            \n",
    "            kfold_array_train[l] += mod_train\n",
    "            kfold_array_test[l] += mod_test\n",
    "            \n",
    "            l += 1\n",
    "            \n",
    "        index_for_cv += number_of_rows\n",
    "\n",
    "    X = np.concatenate(X_array)\n",
    "    y = np.concatenate(y_array)\n",
    "\n",
    "    sc = MinMaxScaler()    \n",
    "    X_scaled = sc.fit_transform(X) \n",
    "    X_scaled = X_scaled.reshape(X.shape[0], lookback, n_features)\n",
    "    X_scaled_windows.append(X_scaled)\n",
    "\n",
    "    \n",
    "# final input is X_scaled_windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom scoring\n",
    "\n",
    "# combining intervals\n",
    "def customise_score(y_testt, y_predd, offset = 5, mark_as=1):\n",
    "    \n",
    "    \n",
    "    y_t = np.copy(y_testt)\n",
    "    y_p = np.copy(y_predd)\n",
    "\n",
    "    \n",
    "    # Fill-in gaps betwwen test\n",
    "    for i in range(len(y_t)):\n",
    "        if y_t[i] and any(y_t[i+1:i+offset+1]):\n",
    "            for j in range(1,offset+1):\n",
    "                if y_t[i+j]:\n",
    "                    break\n",
    "                else:\n",
    "                    y_t[i+j] = mark_as\n",
    "        \n",
    "    # Fill-in gaps betwwen pred\n",
    "    for i in range(len(y_p)):\n",
    "        if y_p[i] and any(y_p[i+1:i+offset+1]):\n",
    "            for j in range(1,offset+1):\n",
    "                if y_p[i+j]:\n",
    "                    break\n",
    "                else:\n",
    "                    y_p[i+j] = mark_as\n",
    "                \n",
    "    return y_t, y_p\n",
    "\n",
    "# counting intervals\n",
    "\n",
    "def customise_score_for_readable(y_testt, y_predd, offset = 8, offset_pred = 8, mark_as = 1, mark_as_inverse = 0):\n",
    "    \n",
    "    \n",
    "    y_t = np.copy(y_testt)\n",
    "    y_p = np.copy(y_predd)\n",
    "\n",
    "\n",
    "    # Fill-in gaps between test marked True Classes\n",
    "    for i in range(len(y_t)):\n",
    "        if y_t[i] and any(y_t[i+1:i+offset+1]):\n",
    "            for j in range(1,offset+1):\n",
    "                if y_t[i+j]:\n",
    "                    break\n",
    "                else:\n",
    "                    y_t[i+j] = mark_as\n",
    "                    \n",
    "                    \n",
    "    # Fill-in gaps between pred marked True Classes\n",
    "    for i in range(len(y_p)):\n",
    "        if y_p[i] and any(y_p[i+1:i+offset_pred+1]):\n",
    "            for j in range(1,offset_pred+1):\n",
    "                if y_p[i+j]:\n",
    "                    break\n",
    "                else:\n",
    "                    y_p[i+j] = mark_as\n",
    "                \n",
    "    return y_t, y_p\n",
    "            \n",
    "\n",
    "def customise_score_readable(*args, **kwargs):\n",
    "   \n",
    "    y_t, y_p = customise_score_for_readable(*args, **kwargs)\n",
    "    \n",
    "    if len(y_t) != len(y_p):\n",
    "        raise Exception(\"Invalid length od y_p and y_t, should be same\")\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    new_y_t = []\n",
    "    new_y_p = []\n",
    "    \n",
    "    \n",
    "    num_TN = 1\n",
    "    \n",
    "    # find TP and Fn\n",
    "    \n",
    "    while i < len(y_t):\n",
    "        if y_t[i]:\n",
    "            j = 1\n",
    "            while y_t[i+j]:\n",
    "                j += 1\n",
    "            \n",
    "            if any(y_p[i:i+j]):\n",
    "                new_y_t.append(1)\n",
    "                new_y_p.append(1)\n",
    "                num_TN += 1\n",
    "                i = i + j\n",
    "                continue\n",
    "            else:\n",
    "                new_y_t.append(1)\n",
    "                new_y_p.append(0)\n",
    "                i = i + j\n",
    "                \n",
    "        i += 1\n",
    "    \n",
    "    # find TN - they dont matter- but number same as number of anomaly zones\n",
    "    \n",
    "    for i in range(num_TN):\n",
    "        new_y_t.append(0)\n",
    "        new_y_p.append(0)\n",
    "    \n",
    "    \n",
    "    # find FP\n",
    "                \n",
    "    while i < len(y_p):\n",
    "        if y_p[i]:\n",
    "            j = 1\n",
    "            while y_p[i+j]:\n",
    "                j += 1\n",
    "            \n",
    "            if not any(y_t[i:i+j]):\n",
    "                new_y_t.append(0)\n",
    "                new_y_p.append(1)\n",
    "                i = i + j\n",
    "                continue\n",
    "            else:\n",
    "                i = i + j\n",
    "                continue\n",
    "        i += 1\n",
    "        \n",
    "    \n",
    "    return new_y_t, new_y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define keras model\n",
    "\n",
    "def getModel():\n",
    "    lr = 0.0001\n",
    "\n",
    "    input_branches = []\n",
    "    output_branches = []\n",
    "\n",
    "    for i in range(len(window_sizes)):\n",
    "        visible = Input(shape=(lookback,n_features))\n",
    "        conv1 = Conv1D(filters=16, kernel_size=3, activation='relu')(visible)\n",
    "        pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "\n",
    "        input_branches.append(visible)\n",
    "        output_branches.append(pool1)\n",
    "    merge = concatenate(output_branches)\n",
    "\n",
    "    conv2 = Conv1D(filters=64, kernel_size=9, activation='relu')(merge)\n",
    "    pool2 = MaxPooling1D(pool_size=4)(conv2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "\n",
    "    hidden1 = Dense(256, activation='relu')(flat2)\n",
    "\n",
    "    dropout1 = Dropout(0.4)(hidden1)\n",
    "\n",
    "    hidden2 = Dense(128, activation='relu')(dropout1)\n",
    "\n",
    "    norm2 = Dropout(0.4)(hidden2)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(norm2)\n",
    "    model = Model(inputs=input_branches, outputs=output)\n",
    "\n",
    "    adam = optimizers.Adam(lr)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy',metrics=['accuracy',km.precision(), km.recall()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "runda = 1\n",
    "\n",
    "for indexindex in range(num_splits):\n",
    "    \n",
    "    train = kfold_array_train[indexindex]\n",
    "    test = kfold_array_test[indexindex]\n",
    "    \n",
    "    X_train_win_arr = []\n",
    "    X_valid_win_arr = []\n",
    "    \n",
    "    \n",
    "    y_train = y[train]\n",
    "    y_valid = y[test]\n",
    "    \n",
    "    \n",
    "    for X_window in X_scaled_windows:\n",
    "        \n",
    "        X_train_win_arr.append(X_window[train])\n",
    "        X_valid_win_arr.append(X_window[test])\n",
    "        \n",
    "\n",
    "    model = getModel()\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
    "\n",
    "    history = model.fit(X_train_win_arr, y_train, batch_size=128, epochs=20, verbose=2, validation_data=(X_valid_win_arr,y_valid), class_weight=class_weights, callbacks= [es])\n",
    "    \n",
    "    # show history\n",
    "    print(history.history.keys())\n",
    "    print(\"----------------------------\")\n",
    "    print(\"številka folda\",runda)\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['precision'])\n",
    "    plt.plot(history.history['val_precision'])\n",
    "    plt.title('Model precision')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['recall'])\n",
    "    plt.plot(history.history['val_recall'])\n",
    "    plt.title('Model recall')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    y_test = y_valid\n",
    "    X_test_scaled_windows = X_valid_win_arr\n",
    "\n",
    "    y_true, y_pred = y_test, model.predict(X_test_scaled_windows)\n",
    "    fpr, tpr, threshold = roc_curve(y_true, y_pred)\n",
    "\n",
    "    results = model.evaluate(X_test_scaled_windows, y_true)\n",
    "    print('test loss, test acc, test prec, test recall:', results)\n",
    "\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(\"BREZ PADDINGA\")\n",
    "    #no Padding\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    threshold_fixed = 0.5\n",
    "    pred_y = [1 if e > threshold_fixed else 0 for e in y_pred]\n",
    "    conf_matrix = confusion_matrix(y_true,pred_y)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "    plt.title(\"Matrika zamenjav\")\n",
    "    plt.ylabel('Označen razred')\n",
    "    plt.xlabel('Napovedan razred')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"classification report za območja brez paddinga\")\n",
    "    print(classification_report(y_true, pred_y))\n",
    "\n",
    "\n",
    "\n",
    "    #with Padding\n",
    "    print(\"S PADDINGOM\")\n",
    "    y_true, pred_y = customise_score(y_true, pred_y,10)\n",
    "    fpr, tpr, threshold = roc_curve(y_true, pred_y)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    conf_matrix = confusion_matrix(y_true,pred_y)\n",
    "\n",
    "\n",
    "    plt.title('ROC - združevanje intervalov')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "    plt.title(\"Matrika zamenjav - združevanje intervalov\")\n",
    "    plt.ylabel('Označen razred')\n",
    "    plt.xlabel('Napovedan razred')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"classification report za območja padding\")\n",
    "    print(classification_report(y_true, pred_y))\n",
    "\n",
    "\n",
    "    # counting intervals\n",
    "    print(\"ŠTETJE INTERVALOV\")\n",
    "\n",
    "    y_true, y_pred = y_test, model.predict(X_test_scaled_windows)\n",
    "    threshold_fixed = 0.5\n",
    "    pred_y = [1 if e > threshold_fixed else 0 for e in y_pred]\n",
    "\n",
    "    y_true, pred_y = customise_score_readable(y_true, pred_y, offset = 10, offset_pred = 10)\n",
    "    fpr, tpr, threshold = roc_curve(y_true, pred_y)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    conf_matrix = confusion_matrix(y_true,pred_y)\n",
    "\n",
    "\n",
    "    plt.title('ROC - štetje intervalov')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "    plt.title(\"Matrika zamenjav - štetje območij anomalij\")\n",
    "    plt.ylabel('Označen razred')\n",
    "    plt.xlabel('Napovedan razred')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"classification report za območje štetja intervalov\")\n",
    "    print(classification_report(y_true, pred_y))\n",
    "    \n",
    "    runda += 1\n",
    "    \n",
    "    if indexindex != 4:\n",
    "        K.clear_session()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
